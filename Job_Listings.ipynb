{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02d78a7",
   "metadata": {},
   "source": [
    "**Job listings Database cleaning project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e58bb4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#indian_df = pd.read_csv('indian_database.csv')\n",
    "india_df = pd.read_csv('job_cleanData.csv')\n",
    "canada_df = pd.read_csv('linkedin-jobs-canada.csv')\n",
    "usa_df = pd.read_csv('linkedin-jobs-usa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1612684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5587 entries, 0 to 5586\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   title          5587 non-null   object\n",
      " 1   company        5587 non-null   object\n",
      " 2   onsite_remote  5587 non-null   object\n",
      " 3   criteria       5587 non-null   object\n",
      " 4   industry       5587 non-null   object\n",
      " 5   level          5587 non-null   object\n",
      " 6   country        5587 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 305.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#This segment drops non-relevant columns for future analysis.\n",
    "#Additionally, I also renamed some columns in order to have them with the same name as the other dataframes (Canada and USA).\n",
    "#Second to last line is used to identify the data from this df once all are concatenated. Each df row will have its country info.\n",
    "\n",
    "india_df = india_df.drop(columns=['City', 'job_ID', 'company_id', 'involvement', 'employees_count', 'linkedin_followers', 'details_id', 'State', 'total_applicants'])\n",
    "india_df.rename(columns={'designation':'title', 'name':'company', 'work_type':'onsite_remote', 'job_details':'criteria'}, inplace=True)\n",
    "india_df['country'] = 'India'\n",
    "print(india_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7e4623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2773 entries, 0 to 2772\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   title          2773 non-null   object\n",
      " 1   company        2773 non-null   object\n",
      " 2   onsite_remote  2773 non-null   object\n",
      " 3   criteria       2773 non-null   object\n",
      " 4   posted_date    2773 non-null   object\n",
      " 5   country        2773 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 130.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#This section is doing pretty much the same as the last one.\n",
    "#I dropped non-relevant columns and added the country tag to all rows for concatenation. \n",
    "\n",
    "canada_df = canada_df.drop(columns=['description', 'salary', 'link', 'location'])\n",
    "canada_df['country'] = 'Canada'\n",
    "canada_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6106e2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2845 entries, 0 to 2844\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   title          2845 non-null   object\n",
      " 1   company        2845 non-null   object\n",
      " 2   onsite_remote  2845 non-null   object\n",
      " 3   criteria       2845 non-null   object\n",
      " 4   posted_date    2845 non-null   object\n",
      " 5   country        2845 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 133.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#This section is doing pretty much the same as the last one.\n",
    "#I dropped non-relevant columns and added the country tag to all rows for concatenation. \n",
    "\n",
    "usa_df = usa_df.drop(columns=['salary', 'location', 'description', 'link'])\n",
    "usa_df['country'] = 'USA'\n",
    "usa_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53fc2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11205 entries, 0 to 2844\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   title          11205 non-null  object        \n",
      " 1   company        11205 non-null  object        \n",
      " 2   onsite_remote  11205 non-null  object        \n",
      " 3   criteria       11205 non-null  object        \n",
      " 4   industry       5587 non-null   object        \n",
      " 5   level          5587 non-null   object        \n",
      " 6   country        11205 non-null  object        \n",
      " 7   posted_date    11205 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(7)\n",
      "memory usage: 787.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#This part concatenates all dfs\n",
    "#Further columns were dropped after realising lack of relevance or way too much nulls. \n",
    "#posted_date variable type updated to pandas datetime + filling nulls with standard date '2022-01-01', nulls were indeed identified as data from 2022. No day or month was found.\n",
    "\n",
    "complete_df = pd.concat([india_df, canada_df, usa_df])\n",
    "complete_df.drop(columns=['industry'])\n",
    "complete_df['posted_date'] = pd.to_datetime(complete_df['posted_date'], format='%Y-%m-%d', errors='coerce')\n",
    "complete_df['posted_date'] = complete_df['posted_date'].fillna(pd.Timestamp('2022-01-01'))\n",
    "complete_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a30c073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    }
   ],
   "source": [
    "#Identify unique values for 'title' column\n",
    "#clean and standardize names with .lower(), .strip(), and regex.\n",
    "\n",
    "complete_df['title_cleaned'] = (\n",
    "    complete_df['title']\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r'\\b(senior|junior|lead|remote|onsite|hybrid|freelance|intern|contract|recent|graduate)\\b', '', regex=True)\n",
    "    .str.replace(r'\\(\\s*\\)', '', regex=True)\n",
    "    .str.replace(r'[-–—]', ' ', regex=True)\n",
    "    .str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    .str.replace(r'\\s+', ' ', regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "print(complete_df.title_cleaned.nunique())\n",
    "titles_df = complete_df['title_cleaned'].value_counts()\n",
    "complete_df['title'] = complete_df['title_cleaned']\n",
    "complete_df.drop(columns=['title_cleaned'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd49577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I used AI(Copilot) to determine the best semantic mapping in order to standardize title names.\n",
    "#I pasted all unique names on Copilot and asked to create a semantic map. Here is the result.\n",
    "#I checked for un-categorized titles and updated the map in order to categorize the remaining ones. \n",
    "\n",
    "title_map = {\n",
    "    # Data Analyst Cluster\n",
    "    'data analyst': 'data analyst',\n",
    "    'data analytics': 'data analyst',\n",
    "    'analyst': 'data analyst',\n",
    "    'data analytics analyst': 'data analyst',\n",
    "    'data analystdeveloper': 'data analyst',\n",
    "    'data analyst operations': 'data analyst',\n",
    "    'data analyst loans': 'data analyst',\n",
    "    'data analystoracle': 'data analyst',\n",
    "    'data analyst marketing': 'data analyst',\n",
    "    'data analyst apac marketplace': 'data analyst',\n",
    "    'data analyst toronto on': 'data analyst',\n",
    "    'data analyst trilogy 60000year usd': 'data analyst',\n",
    "    'data analyst analytics insights toronto on': 'data analyst',\n",
    "    'data analyst with guidewire experience us canada': 'data analyst',\n",
    "    'data analyst vancouver bc': 'data analyst',\n",
    "    'data analystforecasting specialist': 'data analyst',\n",
    "    'data analyst c117': 'data analyst',\n",
    "    'data analyst 12 month': 'data analyst',\n",
    "    'data analyst pythonsql': 'data analyst',\n",
    "    'data analyst reporting': 'data analyst',\n",
    "    'data analyst flight pricing optimization': 'data analyst',\n",
    "    'sector data analyst data driven investing': 'data analyst',\n",
    "    'data administratordata analyst': 'data analyst',\n",
    "    'commercial data analyst': 'data analyst',\n",
    "    'data analyst powerbi': 'data analyst',\n",
    "    'data analyst land': 'data analyst',\n",
    "    'operational data analyst': 'data analyst',\n",
    "    'campaigndata analyst': 'data analyst',\n",
    "    'entry level data analyst': 'data analyst',\n",
    "    'data analyst money': 'data analyst',\n",
    "    'data analystcollector': 'data analyst',\n",
    "    'data analyst i': 'data analyst',\n",
    "    'data analyst i entry level': 'data analyst',\n",
    "    'data analyst us': 'data analyst',\n",
    "    'data analyst sql operations': 'data analyst',\n",
    "    'data analyst sql': 'data analyst',\n",
    "    'data analyst global': 'data analyst',\n",
    "    'wfhdata analyst': 'data analyst',\n",
    "    'data analyst iii': 'data analyst',\n",
    "    'data analyst sql teraform tableau iii': 'data analyst',\n",
    "    'associate data analyst': 'data analyst',\n",
    "    'data analyst 100m valuation': 'data analyst',\n",
    "    'data analyst weekly schedule': 'data analyst',\n",
    "    'group data analyst': 'data analyst',\n",
    "    'consultantdata analyst': 'data analyst',\n",
    "    'data analyst energy': 'data analyst',\n",
    "    'data analyst entry level': 'data analyst',\n",
    "    'sr data analyst': 'data analyst',\n",
    "    'hr data analyst': 'data analyst',\n",
    "    'quality data analyst': 'data analyst',\n",
    "    'data entry analyst risk': 'data analyst',\n",
    "    'data entry jr analyst 6 month': 'data analyst',\n",
    "    'market conduct data analyst 4 month co op': 'data analyst',\n",
    "    'sr market data analyst': 'data analyst',\n",
    "    'principal data analyst': 'data analyst',\n",
    "    'data analyst loanscapital markets': 'data analyst',\n",
    "    'data analyst consultant fire ems': 'data analyst',\n",
    "    'future opportunities data analyst report specialist': 'data analyst',\n",
    "\n",
    "    # Data Scientist & ML Cluster\n",
    "    'data scientist': 'data scientist',\n",
    "    'data science analyst': 'data scientist',\n",
    "    'analytics engineer': 'data scientist',\n",
    "    'analyst data science en': 'data scientist',\n",
    "    'analyst data science fr': 'data scientist',\n",
    "    'analyst global data and analytics': 'data scientist',\n",
    "    'analyst data and analytics': 'data scientist',\n",
    "    'analyst data visualization': 'data scientist',\n",
    "    'analyst cyber governance data analytics': 'data scientist',\n",
    "    'data visualization analyst': 'data scientist',\n",
    "    'data visualization developeranalyst': 'data scientist',\n",
    "    'gaming data analyst': 'data scientist',\n",
    "    'cognitive data analyst': 'data scientist',\n",
    "    'google cloud platform analytics engineer': 'data scientist',\n",
    "    'google analytics engineer': 'data scientist',\n",
    "    'marketing data analyst': 'data scientist',\n",
    "    'seo data analyst': 'data scientist',\n",
    "\n",
    "    # Data Engineer Cluster\n",
    "    'data engineer': 'data engineer',\n",
    "    'data engineer full time': 'data engineer',\n",
    "    'data engineerbig data engineer': 'data engineer',\n",
    "    'data engineer totogi 60000year usd': 'data engineer',\n",
    "    'data engineer ii': 'data engineer',\n",
    "    'data engineer 1': 'data engineer',\n",
    "    'data engineer azure': 'data engineer',\n",
    "    'data engineer with ai ml analytics platforms': 'data engineer',\n",
    "    'data engineer data aws etl': 'data engineer',\n",
    "\n",
    "    # BI & Reporting Cluster\n",
    "    'business intelligence analyst': 'bi analyst',\n",
    "    'bi analyst': 'bi analyst',\n",
    "    'bi reporting analyst': 'bi analyst',\n",
    "    'business intelligence analyst fpa': 'bi analyst',\n",
    "    'power bi developer': 'bi analyst',\n",
    "    'powerbi specialist': 'bi analyst',\n",
    "\n",
    "    # Other Analyst Roles\n",
    "    'information analyst': 'analyst',\n",
    "    'information governance analyst': 'analyst',\n",
    "    'digital analyst': 'analyst',\n",
    "    'insights analyst': 'analyst',\n",
    "    'data specialist': 'analyst',\n",
    "    'data management': 'analyst',\n",
    "    'quantitative data': 'analyst',\n",
    "    'quantitative trader': 'analyst',\n",
    "    'geospatial analyst available 2023': 'analyst',\n",
    "\n",
    "    # Business Analyst Cluster\n",
    "    'business analyst': 'business analyst',\n",
    "    'business systems analyst': 'business analyst',\n",
    "    'business data analyst': 'business analyst',\n",
    "    'business data analyst finance': 'business analyst',\n",
    "\n",
    "    # Developer Cluster\n",
    "    'developer': 'developer',\n",
    "    'shopify developer': 'developer',\n",
    "    'database developer': 'developer',\n",
    "    'salesforce developer': 'developer',\n",
    "    'golang developer': 'developer',\n",
    "    'net developers': 'developer',\n",
    "    'php developer': 'developer',\n",
    "    'sql developer': 'developer',\n",
    "    'java developer': 'developer',\n",
    "    'python developer': 'developer',\n",
    "    'powerapps developer': 'developer',\n",
    "    'snowflake developer': 'developer',\n",
    "    'angular developer': 'developer',\n",
    "    'oracle developer': 'developer',\n",
    "    'blockchain developer': 'developer',\n",
    "    'c developer': 'developer',\n",
    "    'ruby on rails developer': 'developer',\n",
    "    'game developer': 'developer',\n",
    "    'mainframe developer': 'developer',\n",
    "    'unity developer': 'developer',\n",
    "    'mobile application developer': 'developer',\n",
    "    'full stack developer': 'developer',\n",
    "    'web developer': 'developer',\n",
    "    'drupal developer': 'developer',\n",
    "    'wordpress developer': 'developer',\n",
    "    'backend developer': 'developer',\n",
    "    'node js developer': 'developer',\n",
    "    'sap developer': 'developer',\n",
    "    'vuejs developer': 'developer',\n",
    "    'reactjs developer': 'developer',\n",
    "    'bigdata developer': 'developer',\n",
    "    'job opportunity data stage developer': 'developer',\n",
    "\n",
    "    # AI & Robotics Cluster\n",
    "    'ai engineer': 'ai engineer',\n",
    "    'robotics': 'ai engineer',\n",
    "\n",
    "    # QA & Testing\n",
    "    'software testing': 'qa engineer',\n",
    "    'quality analyst': 'qa engineer',\n",
    "\n",
    "    # Education & Training\n",
    "    'technical trainerwriterowner': 'trainer',\n",
    "    'professor': 'trainer',\n",
    "    'education and counseling': 'trainer',\n",
    "\n",
    "    # Management & Leadership\n",
    "    'managerial and leadership roles': 'manager',\n",
    "    'project manager': 'manager',\n",
    "    'scrum master': 'manager',\n",
    "    'team project': 'manager',\n",
    "    'head of product': 'manager',\n",
    "    'product specialist': 'manager',\n",
    "\n",
    "    # Finance & Accounting\n",
    "    'accountant': 'finance',\n",
    "    'finance manager': 'finance',\n",
    "    'financial controller': 'finance',\n",
    "\n",
    "    # Marketing & Content\n",
    "    'marketing': 'marketing',\n",
    "    'digital marketing': 'marketing',\n",
    "    'copywriter': 'marketing',\n",
    "    'content writer': 'marketing',\n",
    "    'search engine optimization': 'marketing',\n",
    "\n",
    "    # Sales & Customer Service\n",
    "    'sales executive': 'sales',\n",
    "    'business development manager': 'sales',\n",
    "    'salesperson': 'sales',\n",
    "    'relationship manager': 'sales',\n",
    "    'customer service': 'sales',\n",
    "    'collections specialist': 'sales',\n",
    "\n",
    "    # Miscellaneous\n",
    "    'consultant': 'consultant',\n",
    "    'associate': 'associate',\n",
    "    'researcher': 'researcher',\n",
    "    'co founder': 'executive',\n",
    "    'storage administrator': 'it support',\n",
    "    'technical support analyst': 'it support',\n",
    "    'technology architecture': 'it support',\n",
    "    'online data analyst': 'data analyst',\n",
    "    'bianalytics consultant': 'bi analyst',\n",
    "}\n",
    "title_map.update({\n",
    "    # Data Analyst variants\n",
    "    'data analyst mississauga on': 'data analyst',\n",
    "    'sql data analyst': 'data analyst',\n",
    "    'product data analyst wtfast': 'data analyst',\n",
    "    'product data analyst': 'data analyst',\n",
    "    'data research analyst trilogy 60000year usd': 'data analyst',\n",
    "    'data and reporting analyst': 'data analyst',\n",
    "    'data governance analyst': 'data analyst',\n",
    "    'cybersecurity data analyst': 'data analyst',\n",
    "    'analyste de données': 'data analyst',\n",
    "    'it data analyst sql banking finance': 'data analyst',\n",
    "    'data analysts': 'data analyst',\n",
    "    'cloud data analyst': 'data analyst',\n",
    "    'analyst data operations': 'data analyst',\n",
    "    'data analyst 2': 'data analyst',\n",
    "\n",
    "    # BI Analyst\n",
    "    'bi analyst': 'bi analyst',\n",
    "    'analyste bi': 'bi analyst',\n",
    "\n",
    "    # Developer variants\n",
    "    'front end developer': 'developer',\n",
    "    'frontend developer': 'developer',\n",
    "    'ios developer': 'developer',\n",
    "\n",
    "    # AI & Engineering\n",
    "    'ai engineer': 'ai engineer',\n",
    "    'linux engineer': 'engineer',\n",
    "\n",
    "    # Research & Support\n",
    "    'researcher': 'researcher',\n",
    "    'associate': 'associate',\n",
    "    'executive': 'executive',\n",
    "    'editor': 'marketing',  # or 'content' if you prefer a separate cluster\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aec4a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "title\n",
      "data analyst                 6123\n",
      "developer                    1930\n",
      "qa engineer                   444\n",
      "other developer               395\n",
      "sales                         323\n",
      "business analyst              274\n",
      "other                         230\n",
      "data scientist                205\n",
      "manager                       192\n",
      "other engineering             151\n",
      "internships                   130\n",
      "marketing                     121\n",
      "consultant                     84\n",
      "cloud engineer                 72\n",
      "software engineer              68\n",
      "finance                        63\n",
      "analyst                        59\n",
      "it support                     57\n",
      "devops engineer                49\n",
      "machine learning engineer      42\n",
      "trainer                        41\n",
      "data engineer                  39\n",
      "bi analyst                     37\n",
      "ai engineer                    29\n",
      "associate                      26\n",
      "engineer                       11\n",
      "researcher                      6\n",
      "executive                       4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Mapping used to change 'title' column for new names and standarization \n",
    "complete_df['title'] = complete_df['title'].map(title_map).fillna(complete_df['title'])\n",
    "print(complete_df.title.nunique())\n",
    "print(complete_df['title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69af24bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I standardized the company name column in order to have all of them in lowercase\n",
    "complete_df['company'] = complete_df['company'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d97633e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onsite_remote\n",
      "onsite    4259\n",
      "remote    4133\n",
      "hybrid    2813\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#I used this part to standardize capitalizaiton and spelling on 'onsite_remote' column.\n",
    "complete_df['onsite_remote'] = complete_df['onsite_remote'].str.lower().str.strip().str.replace('-','')\n",
    "print(complete_df['onsite_remote'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e9cc4b",
   "metadata": {},
   "source": [
    "AI Segment (Copilot): Code used to filter and extract common words/keywords from the 'criteria' description column.\n",
    "\n",
    "After reviewing the top 50 words, the decision to drop the column mas made. But instead of dropping the column, a new dataframe without the 'criteria' column was made. Just in case any future NLP modeling is performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6c65d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experience: 19375\n",
      "job: 17708\n",
      "epam: 13760\n",
      "work: 10852\n",
      "data: 10756\n",
      "level: 10284\n",
      "technology: 8744\n",
      "development: 8089\n",
      "global: 7981\n",
      "skills: 7779\n",
      "years: 7624\n",
      "team: 7458\n",
      "services: 7247\n",
      "software: 6995\n",
      "information: 6735\n",
      "knowledge: 6545\n",
      "time: 6499\n",
      "looking: 6489\n",
      "business: 6452\n",
      "platform: 6399\n",
      "remote: 6017\n",
      "applications: 5967\n",
      "join: 5901\n",
      "type: 5871\n",
      "employment: 5802\n",
      "working: 5778\n",
      "function: 5430\n",
      "industries: 5379\n",
      "seniority: 5199\n",
      "application: 4779\n",
      "technical: 4648\n",
      "programs: 4494\n",
      "requirements: 4483\n",
      "projects: 4455\n",
      "learning: 4399\n",
      "design: 4193\n",
      "position: 4136\n",
      "management: 3911\n",
      "opportunities: 3895\n",
      "career: 3893\n",
      "new: 3828\n",
      "strong: 3813\n",
      "systems: 3644\n",
      "financial: 3569\n",
      "including: 3505\n",
      "set: 3504\n",
      "engineering: 3498\n",
      "test: 3410\n",
      "customer: 3310\n",
      "solutions: 3266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Fill missing values and limit to top 1000 words\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
    "\n",
    "# Fit and transform the criteria column\n",
    "X = vectorizer.fit_transform(complete_df['criteria'].fillna(''))\n",
    "\n",
    "# Create a dictionary of word frequencies\n",
    "word_freq = dict(zip(vectorizer.get_feature_names_out(), X.sum(axis=0).A1))\n",
    "\n",
    "# Sort and print top 50 words\n",
    "sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "for word, freq in sorted_words[:50]:\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14bfd8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java: 2992\n",
      "aws: 2293\n",
      "sql: 2218\n",
      "python: 1820\n",
      "agile: 1488\n",
      "azure: 1444\n",
      "javascript: 1415\n",
      "scrum: 658\n",
      "git: 628\n",
      "gcp: 473\n",
      "excel: 450\n",
      "spark: 439\n",
      "jira: 412\n",
      "docker: 411\n",
      "jenkins: 409\n",
      "linux: 403\n",
      "kubernetes: 357\n",
      "hadoop: 271\n",
      "tableau: 267\n",
      "php: 224\n",
      "typescript: 217\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##### code from copilot to look for curated skills on 'criteria' column\n",
    "skills_list = [\n",
    "    'python', 'java', 'javascript', 'c++', 'c#', 'typescript', 'go', 'ruby', 'php', 'swift', 'kotlin', 'r',\n",
    "    'sql', 'excel', 'tableau', 'powerbi', 'sas', 'spark', 'hadoop',\n",
    "    'aws', 'azure', 'gcp',\n",
    "    'docker', 'kubernetes', 'jenkins', 'git',\n",
    "    'tensorflow', 'pytorch', 'scikit', 'keras',\n",
    "    'linux', 'bash', 'shell', 'jira', 'agile', 'scrum'\n",
    "]\n",
    "\n",
    "filtered_skills = {word: freq for word, freq in word_freq.items() if word in skills_list}\n",
    "sorted_skills = sorted(filtered_skills.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for skill, freq in sorted_skills:\n",
    "    print(f\"{skill}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bf5260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consolidation of new dataframe without the 'criteria' column\n",
    "#renaming of 'title' to 'job_title'\n",
    "#renaming of 'company' to 'company_name'\n",
    "jobs_df = complete_df.drop(columns=['criteria'])\n",
    "jobs_df.rename(columns={'title':'job_title', 'company':'company_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d91e66",
   "metadata": {},
   "source": [
    "Column cleaning process continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07bee3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industry\n",
      "unknown                                                7569\n",
      "it services and it consulting                          2498\n",
      "software development                                    146\n",
      "information technology & services                       127\n",
      "technology information and internet                      99\n",
      "financial services                                       91\n",
      "staffing and recruiting                                  90\n",
      "business consulting and services                         73\n",
      "human resources services                                 44\n",
      "information services                                     31\n",
      "advertising services                                     27\n",
      "non-profit organizations                                 27\n",
      "retail                                                   22\n",
      "telecommunications                                       22\n",
      "motor vehicle manufacturing                              20\n",
      "outsourcing and offshoring consulting                    15\n",
      "pharmaceutical manufacturing                             12\n",
      "higher education                                         11\n",
      "hospitals and health care                                11\n",
      "market research                                          10\n",
      "accounting                                               10\n",
      "insurance                                                 9\n",
      "banking                                                   9\n",
      "e-learning providers                                      9\n",
      "research services                                         8\n",
      "manufacturing                                             8\n",
      "computer games                                            8\n",
      "transportation logistics supply chain and storage         7\n",
      "internet publishing                                       7\n",
      "translation and localization                              6\n",
      "consumer services                                         6\n",
      "computers and electronics manufacturing                   6\n",
      "computer and network security                             6\n",
      "human resources                                           6\n",
      "wellness and fitness services                             5\n",
      "oil and gas                                               5\n",
      "civil engineering                                         5\n",
      "appliances electrical and electronics manufacturing       5\n",
      "renewable energy semiconductor manufacturing              4\n",
      "semiconductor manufacturing                               4\n",
      "wireless services                                         4\n",
      "medical equipment manufacturing                           4\n",
      "education administration programs                         4\n",
      "airlines and aviation                                     4\n",
      "retail groceries                                          4\n",
      "biotechnology research                                    4\n",
      "aviation & aerospace                                      3\n",
      "professional training and coaching                        3\n",
      "spectator sports                                          3\n",
      "law practice                                              3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#'industry' column standarization\n",
    "jobs_df['industry'] = jobs_df['industry'].str.lower().str.strip()\n",
    "jobs_df['industry'] = jobs_df['industry'].replace('not avilable', 'unknown')\n",
    "jobs_df['industry'] = jobs_df['industry'].fillna('unknown')\n",
    "print(jobs_df['industry'].value_counts().head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b4f84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seniority\n",
      "unknown       7681\n",
      "mid-senior    2932\n",
      "associate      400\n",
      "entry          127\n",
      "executive       34\n",
      "director        24\n",
      "internship       7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#'level' column standarization\n",
    "jobs_df['level'] = jobs_df['level'].str.lower().str.strip()\n",
    "jobs_df['level'] = jobs_df['level'].replace('not avilable', 'unknown')\n",
    "jobs_df['level'] = jobs_df['level'].str.replace(r'\\s+level$', '', regex=True).str.strip()\n",
    "jobs_df['level'] = jobs_df['level'].fillna('unknown')\n",
    "jobs_df.rename(columns={'level':'seniority'}, inplace=True)\n",
    "print(jobs_df['seniority'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8bb3ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11205 entries, 0 to 2844\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   job_title      11205 non-null  object        \n",
      " 1   company_name   11205 non-null  object        \n",
      " 2   onsite_remote  11205 non-null  object        \n",
      " 3   industry       11205 non-null  object        \n",
      " 4   seniority      11205 non-null  object        \n",
      " 5   country        11205 non-null  object        \n",
      " 6   posted_date    11205 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(6)\n",
      "memory usage: 700.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(jobs_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a38bfddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract skills from each row's criteria text\n",
    "def extract_skills(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    text_lower = text.lower()\n",
    "    return [skill for skill in skills_list if skill in text_lower]\n",
    "\n",
    "# Apply the function to create a new column with skill lists\n",
    "jobs_df['skills'] = complete_df['criteria'].apply(extract_skills)\n",
    "\n",
    "# Convert the list of skills into a string for Power BI\n",
    "jobs_df['skills_str'] = jobs_df['skills'].apply(lambda x: ';'.join(x))\n",
    "\n",
    "# Drop the 'skills' list column and keep only the string version\n",
    "jobs_df.drop(columns=['skills'], inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
